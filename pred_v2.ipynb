{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from lib.utils.utils import process_model_dict\n",
    "from lib.utils.visualizer import Visualizer\n",
    "from lib.utils.video_iterator import VideoIterator\n",
    "from lib.utils.inference_helper import InferenceHelper\n",
    "from lib.models.unet_adaptive_bins_legacy import UnetAdaptiveBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model ()..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bharath/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Removing last two layers (global_pool & classifier).\n",
      "Building Encoder-Decoder model..Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bharath/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH = 10\n",
    "FRAME_SIZE = (640, 480)\n",
    "\n",
    "model_depth = UnetAdaptiveBins.build(n_bins = 256, min_val = MIN_DEPTH, max_val = MAX_DEPTH)\n",
    "pretrained_ckpt = process_model_dict('weights/AdaBins_nyu.pt')\n",
    "model_depth.load_state_dict(pretrained_ckpt)\n",
    "\n",
    "model_seg = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained = True)\n",
    "\n",
    "infer = InferenceHelper(model_depth, model_seg, MIN_DEPTH, MAX_DEPTH, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/bharath/code/Pros/Multi-Exit-Dense-Networks/data/test/image_5.jpg')\n",
    "img = cv2.resize(img, FRAME_SIZE)\n",
    "\n",
    "bin_center, pred_depth, pred_seg = infer.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': -0.05060184209509067, 'y': -0.8272060402743945, 'z': -2.0001673981220023},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe2dc207f344cf7a9ba6792ee067022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorscale': [[0.0, '#440154'], [0.1111111111111111, '#482878'],\n",
       "               â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = go.Surface(\n",
    "    z = pred_depth.squeeze(),\n",
    "    colorscale='viridis'\n",
    ")\n",
    "fig = go.FigureWidget(data)\n",
    "fig.layout.scene.camera = camera\n",
    "fig.data[0].update(surfacecolor=img[:,:,0])\n",
    "fig.update_layout(width = 1000, height = 800)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_frames = int(1 / SAMPLING_RATE)\n",
    "vid_iter = VideoIterator('data/test/test3.mkv', FRAME_SIZE)\n",
    "pred_prev = np.ones((480, 640)) * 1.7\n",
    "\n",
    "for i, frame in enumerate(vid_iter):\n",
    "    if i % skip_frames == 0:\n",
    "        _, pred_depth, pred_seg = infer.predict(frame, is_depth = True, is_seg = False)\n",
    "        pred_prev = (pred_prev + pred_depth.squeeze()) / 2\n",
    "        fig.data[0].z = pred_prev\n",
    "        fig.data[0].update(surfacecolor = frame[:,:,0])\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "253caa359b0bcdcc0a28cdbb8d6106cd3ddb94c7ff3cbb7c0abfa6f9d6d5e7ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mess_cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
