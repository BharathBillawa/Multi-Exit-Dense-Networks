{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from lib.utils.utils import process_model_dict\n",
    "from lib.utils.visualizer import Visualizer\n",
    "from lib.utils.video_iterator import VideoIterator\n",
    "from lib.utils.inference_helper import InferenceHelper\n",
    "from lib.models.unet_adaptive_bins_legacy import UnetAdaptiveBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharath/anaconda3/envs/mess_cv/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning:\n",
      "\n",
      "CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811806235/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model ()..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bharath/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Removing last two layers (global_pool & classifier).\n",
      "Building Encoder-Decoder model..Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bharath/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH = 10\n",
    "FRAME_SIZE = (640, 480)\n",
    "\n",
    "model_depth = UnetAdaptiveBins.build(n_bins = 256, min_val = MIN_DEPTH, max_val = MAX_DEPTH)\n",
    "pretrained_ckpt = process_model_dict('weights/AdaBins_nyu.pt')\n",
    "model_depth.load_state_dict(pretrained_ckpt)\n",
    "\n",
    "model_seg = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained = True)\n",
    "\n",
    "infer = InferenceHelper(model_depth, model_seg, MIN_DEPTH, MAX_DEPTH, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43085d2adc141e386ec8d34f6a6f2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'image',\n",
       "              'uid': 'c97f81ad-b246-4330-b50a-5372d6f6252d',\n",
       "   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('/home/bharath/code/Pros/Multi-Exit-Dense-Networks/data/test/image_5.jpg')\n",
    "img = cv2.resize(img, FRAME_SIZE)\n",
    "\n",
    "bin_center, pred_depth, pred_seg = infer.predict(img)\n",
    "depth_vis = Visualizer(1200, 1000, img, pred_depth, pred_seg)\n",
    "\n",
    "depth_vis.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 0.05\n",
    "DEPTH_SAMPLING_WEIGHT = 2\n",
    "SEG_SAMPLING_WEIGHT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_frames = int(1 / SAMPLING_RATE)\n",
    "vid_iter = VideoIterator('data/test/test3.mkv', FRAME_SIZE)\n",
    "\n",
    "depth_samp_count = 0\n",
    "seg_samp_count  = 0\n",
    "\n",
    "for i, frame in enumerate(vid_iter):\n",
    "    if i % skip_frames == 0:\n",
    "        depth_vis.update_img(frame)\n",
    "        if depth_samp_count < DEPTH_SAMPLING_WEIGHT:\n",
    "            depth_samp_count += 1\n",
    "            _, pred_depth, pred_seg = infer.predict(frame, is_depth = True, is_seg = False)\n",
    "            depth_vis.update_depth(pred_depth.squeeze(), frame)\n",
    "\n",
    "        elif seg_samp_count < SEG_SAMPLING_WEIGHT - 1:\n",
    "            seg_samp_count += 1\n",
    "            _, pred_depth, pred_seg = infer.predict(frame, is_depth = False, is_seg = True)\n",
    "            depth_vis.update_seg(pred_seg.squeeze())\n",
    "\n",
    "        else:\n",
    "            depth_samp_count = 0\n",
    "            seg_samp_count = 0\n",
    "            _, pred_depth, pred_seg = infer.predict(frame, is_depth = False, is_seg = True)\n",
    "            depth_vis.update_seg(pred_seg.squeeze())\n",
    "        \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "253caa359b0bcdcc0a28cdbb8d6106cd3ddb94c7ff3cbb7c0abfa6f9d6d5e7ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mess_cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
